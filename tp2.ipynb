{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus.reader.wordnet import NOUN, ADJ, ADV, VERB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\user.user-\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\user.user-PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\user.user-\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package sentiwordnet to C:\\Users\\user.user-\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Téléchargement des ressources nécessaires\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('sentiwordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire pour la correspondance entre les POS tags de NLTK et ceux de WordNet\n",
    "POS_TAG_MAP = {\n",
    "    'N': 'n',  # Noun\n",
    "    'V': 'v',  # Verb\n",
    "    'R': 'r',  # Adverb\n",
    "    'J': 'a'   # Adjective\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les POS tags de NLTK à ceux utilisés par WordNet\n",
    "def get_wordnet_pos(pos_tag):\n",
    "    return POS_TAG_MAP.get(pos_tag[0], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse de sentiment d'une phrase sans gestion de la négation\n",
    "def analyze_sentiment(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    print(\"Tokens:\", tokens)\n",
    "\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    print(\"POS Tags:\", pos_tags)\n",
    "\n",
    "    wnl = WordNetLemmatizer()\n",
    "    lemmas = [wnl.lemmatize(token) for token in tokens]\n",
    "    print(\"Lemmas:\", lemmas)\n",
    "\n",
    "    total_score = 0\n",
    "    for token, pos in zip(lemmas, pos_tags):\n",
    "        wn_pos = get_wordnet_pos(pos[1])\n",
    "        if wn_pos:\n",
    "            senti_synsets = list(swn.senti_synsets(token, wn_pos))\n",
    "            score=0\n",
    "            if senti_synsets:\n",
    "                score = senti_synsets[0].pos_score() - senti_synsets[0].neg_score()\n",
    "                print(\"Token: {}, Positivity: {}, Negativity: {}, Objectivity: {}, Score: {}\".format(token, senti_synsets[0].pos_score(), senti_synsets[0].neg_score(), senti_synsets[0].obj_score(), score))\n",
    "\n",
    "            total_score += score\n",
    "    print(\"Total Sentiment Score:\", total_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse de sentiment d'une phrase avec gestion de la négation\n",
    "\n",
    "# Méthode 1: inverser la polarité du mot qui vient juste après la négation\n",
    "def analyze_sentiment_with_negation1(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    print(\"Tokens:\", tokens)\n",
    "\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    print(\"POS Tags:\", pos_tags)\n",
    "\n",
    "    wnl = WordNetLemmatizer()\n",
    "    lemmas = [wnl.lemmatize(token) for token in tokens]\n",
    "    print(\"Lemmas:\", lemmas)\n",
    "\n",
    "    total_score = 0\n",
    "    negative_words = [\"not\", \"never\", \"no\", \"n't\", \"hardly\", \"scarcely\", \"barely\"]\n",
    "    negate = False\n",
    "    for token, pos in zip(lemmas, pos_tags):\n",
    "        wn_pos = get_wordnet_pos(pos[1])\n",
    "        if wn_pos:\n",
    "            senti_synsets = list(swn.senti_synsets(token, wn_pos))\n",
    "            if senti_synsets:\n",
    "                score = senti_synsets[0].pos_score() - senti_synsets[0].neg_score()\n",
    "                if negate:\n",
    "                    score = -score\n",
    "                total_score += score\n",
    "                print(\"Token: {}, Positivity: {}, Negativity: {}, Objectivity: {}, Score: {}\".format(token, senti_synsets[0].pos_score(), senti_synsets[0].neg_score(), senti_synsets[0].obj_score(), score))\n",
    "\n",
    "\n",
    "        # Gestion de la négation (simple)\n",
    "        if token.lower() in negative_words:\n",
    "            negate = True\n",
    "        else:\n",
    "            negate = False\n",
    "\n",
    "    print(\"Total Sentiment Score:\", total_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Méthode 2: inverser la poolarité de tous les mots qui viennent après la négation\n",
    "def analyze_sentiment_with_negation2(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    print(\"Tokens:\", tokens)\n",
    "\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    print(\"POS Tags:\", pos_tags)\n",
    "\n",
    "    wnl = WordNetLemmatizer()\n",
    "    lemmas = [wnl.lemmatize(token) for token in tokens]\n",
    "    print(\"Lemmas:\", lemmas)\n",
    "\n",
    "    total_score = 0\n",
    "    negate = False\n",
    "    negative_words = [\"not\", \"never\", \"no\", \"n't\", \"hardly\", \"scarcely\", \"barely\"]\n",
    "\n",
    "    for token, pos in zip(lemmas, pos_tags):\n",
    "        wn_pos = get_wordnet_pos(pos[1])\n",
    "        if wn_pos:\n",
    "            senti_synsets = list(swn.senti_synsets(token, wn_pos))\n",
    "            if senti_synsets:\n",
    "                score = senti_synsets[0].pos_score() - senti_synsets[0].neg_score()\n",
    "                if negate:\n",
    "                    score = -score\n",
    "                total_score += score\n",
    "                print(\"Token: {}, Positivity: {}, Negativity: {}, Objectivity: {}, Score: {}\".format(token, senti_synsets[0].pos_score(), senti_synsets[0].neg_score(), senti_synsets[0].obj_score(), score))\n",
    "\n",
    "        # Gestion de la négation\n",
    "        if token.lower() in negative_words:\n",
    "            negate = not negate\n",
    "\n",
    "    print(\"Total Sentiment Score:\", total_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyse de sentiment sans négation pour 'I love this beautiful day.':\n",
      "('Tokens:', ['I', 'love', 'this', 'beautiful', 'day', '.'])\n",
      "('POS Tags:', [('I', 'PRP'), ('love', 'VBP'), ('this', 'DT'), ('beautiful', 'JJ'), ('day', 'NN'), ('.', '.')])\n",
      "('Lemmas:', ['I', 'love', 'this', 'beautiful', 'day', '.'])\n",
      "Token: love, Positivity: 0.5, Negativity: 0.0, Objectivity: 0.5, Score: 0.5\n",
      "Token: beautiful, Positivity: 0.75, Negativity: 0.0, Objectivity: 0.25, Score: 0.75\n",
      "Token: day, Positivity: 0.0, Negativity: 0.0, Objectivity: 1.0, Score: 0.0\n",
      "('Total Sentiment Score:', 1.25)\n",
      "\n",
      "Analyse de sentiment avec négation pour 'I do not love this beautiful day.':\n",
      "('Tokens:', ['I', 'do', 'not', 'love', 'this', 'beautiful', 'day', '.'])\n",
      "('POS Tags:', [('I', 'PRP'), ('do', 'VBP'), ('not', 'RB'), ('love', 'VB'), ('this', 'DT'), ('beautiful', 'JJ'), ('day', 'NN'), ('.', '.')])\n",
      "('Lemmas:', ['I', 'do', 'not', 'love', 'this', 'beautiful', 'day', '.'])\n",
      "Token: do, Positivity: 0.0, Negativity: 0.0, Objectivity: 1.0, Score: 0.0\n",
      "Token: not, Positivity: 0.0, Negativity: 0.625, Objectivity: 0.375, Score: -0.625\n",
      "Token: love, Positivity: 0.5, Negativity: 0.0, Objectivity: 0.5, Score: 0.5\n",
      "Token: beautiful, Positivity: 0.75, Negativity: 0.0, Objectivity: 0.25, Score: 0.75\n",
      "Token: day, Positivity: 0.0, Negativity: 0.0, Objectivity: 1.0, Score: 0.0\n",
      "('Total Sentiment Score:', 0.625)\n",
      "\n",
      "Méthode 1: Analyse de sentiment avec négation pour 'I do not love this beautiful day.':\n",
      "('Tokens:', ['I', 'do', 'not', 'love', 'this', 'beautiful', 'day', '.'])\n",
      "('POS Tags:', [('I', 'PRP'), ('do', 'VBP'), ('not', 'RB'), ('love', 'VB'), ('this', 'DT'), ('beautiful', 'JJ'), ('day', 'NN'), ('.', '.')])\n",
      "('Lemmas:', ['I', 'do', 'not', 'love', 'this', 'beautiful', 'day', '.'])\n",
      "Token: do, Positivity: 0.0, Negativity: 0.0, Objectivity: 1.0, Score: 0.0\n",
      "Token: not, Positivity: 0.0, Negativity: 0.625, Objectivity: 0.375, Score: -0.625\n",
      "Token: love, Positivity: 0.5, Negativity: 0.0, Objectivity: 0.5, Score: -0.5\n",
      "Token: beautiful, Positivity: 0.75, Negativity: 0.0, Objectivity: 0.25, Score: 0.75\n",
      "Token: day, Positivity: 0.0, Negativity: 0.0, Objectivity: 1.0, Score: 0.0\n",
      "('Total Sentiment Score:', -0.375)\n",
      "\n",
      "Méthode 2: Analyse de sentiment avec négation pour 'I do not love this beautiful day.':\n",
      "('Tokens:', ['I', 'do', 'not', 'love', 'this', 'beautiful', 'day', '.'])\n",
      "('POS Tags:', [('I', 'PRP'), ('do', 'VBP'), ('not', 'RB'), ('love', 'VB'), ('this', 'DT'), ('beautiful', 'JJ'), ('day', 'NN'), ('.', '.')])\n",
      "('Lemmas:', ['I', 'do', 'not', 'love', 'this', 'beautiful', 'day', '.'])\n",
      "Token: do, Positivity: 0.0, Negativity: 0.0, Objectivity: 1.0, Score: 0.0\n",
      "Token: not, Positivity: 0.0, Negativity: 0.625, Objectivity: 0.375, Score: -0.625\n",
      "Token: love, Positivity: 0.5, Negativity: 0.0, Objectivity: 0.5, Score: -0.5\n",
      "Token: beautiful, Positivity: 0.75, Negativity: 0.0, Objectivity: 0.25, Score: -0.75\n",
      "Token: day, Positivity: 0.0, Negativity: 0.0, Objectivity: 1.0, Score: -0.0\n",
      "('Total Sentiment Score:', -1.875)\n"
     ]
    }
   ],
   "source": [
    "# Analyse de sentiment pour les deux phrases sans gestion de la négation\n",
    "print(\"\\nAnalyse de sentiment sans négation pour 'I love this beautiful day.':\")\n",
    "analyze_sentiment(\"I love this beautiful day.\")\n",
    "\n",
    "print(\"\\nAnalyse de sentiment avec négation pour 'I do not love this beautiful day.':\")\n",
    "analyze_sentiment(\"I do not love this beautiful day.\")\n",
    "\n",
    "# Analyse de sentiment pour la phrase avec gestion de la négation Méthode 1\n",
    "print(\"\\nMéthode 1: Analyse de sentiment avec négation pour 'I do not love this beautiful day.':\")\n",
    "analyze_sentiment_with_negation1(\"I do not love this beautiful day.\")\n",
    "\n",
    "# Analyse de sentiment pour la phrase avec gestion de la négation Méthode 2\n",
    "print(\"\\nMéthode 2: Analyse de sentiment avec négation pour 'I do not love this beautiful day.':\")\n",
    "analyze_sentiment_with_negation2(\"I do not love this beautiful day.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
